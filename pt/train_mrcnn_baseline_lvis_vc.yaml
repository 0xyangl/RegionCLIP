description: train Mask RCNN on LVIS

target:
  vc: resrchvc
  service: amlk8s
  name: ms-shared-v100 # itpscusv100cl  # itplabrr1cl1 # itpeastusv100cl #  itplabrr1cl1

environment:
  image: wangkenpu/pytorch:1.8.0-py39-cuda11.1-cudnn8-ubuntu18.04 # jw2yang/video-pytorch1.7:v0.1
  #registry: docker.io

storage:  
  # By default, the mount path is /mnt/data_storage, /mnt/output_storage
  data_storage:
    storage_account_name: vlpdatasets
    container_name: data
  output_storage:
    storage_account_name: vyiwuzhong
    container_name: phillytools 

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: ./

# exp: train supervised standard Mask RCNN on COCO
search:
  job_template:
    name: train_mask_rcnn_resnet50_baseline_1x_coco80_c4_lr0002
    sku: G16
    sku_count: 1
    command:
    - nvidia-smi
    - bash install.sh
    - python3 ./tools/train_net.py
      --num-gpus 16
      --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml
      OUTPUT_DIR /mnt/output_storage/results/train_mask_rcnn_resnet50_baseline_1x_coco80_c4_lr0002
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      SOLVER.BASE_LR 0.002
      DATALOADER.NUM_WORKERS {num_workers}
      TEST.EVAL_PERIOD 25000
      MODEL.MASK_ON False
      #MODEL.META_ARCHITECTURE ProposalNetwork
      #MODEL.BACKBONE.FREEZE_AT 0
      #MODEL.WEIGHTS ""
    
    submit_args:
      container_args:
        shm_size: 1024G
  max_trials: 1
  type: grid          
  params:
    - name: ims_per_batch
      spec: discrete
      values: [16]
    - name: num_workers
      spec: discrete
      values: [4]

# exp: train CVPR OVR model with their pretrained weights on COCO-48 split
# search:
#   job_template:
#     name: train_mask_rcnn_resnet50_baseline_1x_coco48_lvisopenset08lossandcoco65fpnrpn_CLIPFastRCNN_testall
#     sku: G8
#     sku_count: 1
#     command:
#     - nvidia-smi
#     - bash install.sh
#     - python3 ./tools/train_net.py
#       --num-gpus 8
#       --eval-only
#       --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_CLIP_R_50_C4_1x_ovd_FSD.yaml
#       MODEL.WEIGHTS /mnt/output_storage/results/train_CLIP_fast_rcnn_resnet50_openset_openbaselinefpnrpn_866ids_08bgloss/model_final.pth
#       OUTPUT_DIR /mnt/output_storage/results/train_mask_rcnn_resnet50_baseline_1x_coco48_lvisopenset08lossandcoco65fpnrpn_CLIPFastRCNN_testall
#       SOLVER.IMS_PER_BATCH {ims_per_batch}
#       SOLVER.BASE_LR 0.01
#       DATALOADER.NUM_WORKERS {num_workers}
#       TEST.EVAL_PERIOD 50000
#       MODEL.MASK_ON False
#       MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
#       MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
#       MODEL.CLIP.BG_CLS_LOSS_WEIGHT 0.2
#       MODEL.ROI_HEADS.POSITIVE_FRACTION 1.0
#       MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
#       MODEL.META_ARCHITECTURE CLIPFastRCNN
#       MODEL.CLIP.CROP_REGION_TYPE RPN
#       MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
#       MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco65/fpn/model_final.pth
#       MODEL.ROI_HEADS.NUM_CLASSES 65
#       MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
#       # MODEL.ROI_HEADS.NUM_CLASSES 48
#       # MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco48_cls_emb.pth
#       # MODEL.CLIP.OPENSET_TEST_NUM_CLASSES 65
#       # MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco65_cls_emb.pth
      
#       #--config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
#       #MODEL.WEIGHTS /mnt/output_storage/trained_models/cvpr_ovr_models/cvpr_ovr_pretrained_weights.pth
#       #MODEL.WEIGHTS /mnt/output_storage/results/train_mask_rcnn_resnet50_baseline_1x_coco48_cvprovr/model_final.pth
#       #MODEL.WEIGHTS /mnt/output_storage/results/train_mask_rcnn_resnet50_baseline_1x_coco48_cvprovr_CLIPFastRCNN/model_final.pth
#       #MODEL.WEIGHTS /mnt/output_storage/results/train_CLIP_fast_rcnn_resnet50_openset_openbaselinefpnrpn_866ids_08bgloss/model_final.pth
      
#       #MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
#       #MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/fpn/model_final.pth
#       #MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
#       #MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco65/fpn/model_final.pth
    
#     submit_args:
#       container_args:
#         shm_size: 1024G
#   max_trials: 1
#   type: grid          
#   params:
#     - name: ims_per_batch
#       spec: discrete
#       values: [16]
#     - name: num_workers
#       spec: discrete
#       values: [4]


# exp: CLIPFastRCNN zeroshot inference on COCO with RoIAlign to extract region features (GT / RPN regions)
# search:
#   job_template:
#     name: test_CLIPfastrcnn_rn50_coco65_lvisopenbaselinefpnrpn_zeroshotinf_cvprovr_temp10
#     sku: G4 # G1 # 
#     sku_count: 1
#     command:
#     - nvidia-smi
#     - bash install.sh
#     - python3 ./tools/train_net.py
#       --num-gpus 4
#       --eval-only
#       --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
#       MODEL.WEIGHTS /mnt/output_storage/trained_models/cvpr_ovr_models/cvpr_ovr_pretrained_weights.pth
#       OUTPUT_DIR /mnt/output_storage/results/test_CLIPfastrcnn_rn50_coco65_lvisopenbaselinefpnrpn_zeroshotinf_cvprovr_temp10
#       MODEL.META_ARCHITECTURE CLIPFastRCNN
#       MODEL.CLIP.CROP_REGION_TYPE RPN
#       MODEL.CLIP.IMS_PER_BATCH_TEST 8
#       MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
#       MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
#       MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
#       MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco48_cls_emb.pth
#       MODEL.CLIP.NO_BOX_DELTA True
#       MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco65_cls_emb.pth
#       MODEL.CLIP.RUN_CVPR_OVR True
#       MODEL.MASK_ON False
#       SOLVER.IMS_PER_BATCH {ims_per_batch}
#       DATALOADER.NUM_WORKERS {num_workers}
#       MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
#       MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
#       MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
#       MODEL.CLIP.CLSS_TEMP 10.0

#     submit_args:
#       container_args:
#         shm_size: 1024G
#   max_trials: 1
#   type: grid          
#   params:
#     - name: ims_per_batch
#       spec: discrete
#       values: [16]
#     - name: num_workers
#       spec: discrete
#       values: [4]


# exp: train supervised standard Mask RCNN on LVIS
# search:
#   job_template:
#     name: train_mask_rcnn_resnet50_baseline_gpus8_bs16_lr0.002_1x
#     sku: G8
#     sku_count: 1
#     # aml_mpirun:
#     #   process_count_per_node: 1
#     #   # AML only supports: OpenMpi or IntelMpi
#     #   communicator: "OpenMpi"
#     command:
#     - nvidia-smi
#     - bash install.sh
#     # - export MKL_SERVICE_FORCE_INTEL=1
#     # - MKL_THREADING_LAYER=GNU python3 ./tools/train_net.py
#     - python3 ./tools/train_net.py
#       --num-gpus {num_gpus}
#       --config-file ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
#       OUTPUT_DIR /mnt/output_storage/results/train_mask_rcnn_resnet50_baseline_gpus8_bs16_lr0.002_1x
#       SOLVER.IMS_PER_BATCH {ims_per_batch}
#       SOLVER.BASE_LR 0.002
#       DATALOADER.NUM_WORKERS {num_workers}
#       TEST.EVAL_PERIOD 50000
#       #MODEL.WEIGHTS /mnt/output_storage/trained_models/mrcnn_supervised/c4/model_final.pth
#       #MODEL.META_ARCHITECTURE ProposalNetwork
      
#       #MODEL.WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
#       #MODEL.WEIGHTS /mnt/output_storage/trained_models/mrcnn_supervised/fpn/model_final.pth
#       #MODEL.WEIGHTS /mnt/output_storage/trained_models/mrcnn_supervised/c4/model_final.pth
      
#       #--config-file ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
#       #--config-file ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml
#       #MODEL.BACKBONE.FREEZE_AT 0
#       #MODEL.WEIGHTS ""
      

#     submit_args:
#       container_args:
#         shm_size: 1024G
#   max_trials: 1
#   type: grid          
#   params:
#     - name: num_gpus
#       spec: discrete
#       values: [8]
#     - name: ims_per_batch
#       spec: discrete
#       values: [16]
#     - name: num_workers
#       spec: discrete
#       values: [4]