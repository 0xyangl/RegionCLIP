description: train Mask RCNN on LVIS

target:
  vc: hai1 #resrchvc  # 
  service: amlk8s
  name: ms-shared-v100 # itphyperdgx2cl2 # itpeastusv100cl # itpscusv100cl  #  itpseasiav100cl #  itplabrr1cl1  # 
  #subscription_id: 46da6261-2167-4e71-8b0d-f4a45215ce61

environment:
  image: wangkenpu/pytorch:1.8.0-py39-cuda11.1-cudnn8-ubuntu18.04 # amsword/setup:py36pt17u18cu11 # jw2yang/video-pytorch1.7:v0.1 
  registry: docker.io

storage:  
  # By default, the mount path is /mnt/data_storage, /mnt/output_storage
  data_storage:
    storage_account_name: vlpdatasets
    container_name: data
  output_storage:
    storage_account_name: vyiwuzhong
    container_name: phillytools 

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: ./

search:
  job_template:
    name: LSJ_train_CLIPfastrcnn_rn50_openset_strongfpn400eprpn_866ids_08bgloss_ourclip3m600kcc6790emb
    sku: G16 
    sku_count: 1
    command:
    - nvidia-smi
    - bash install.sh
    - ulimit -n 64000
    # training + evaluation during training
    - python3 ./tools/train_net.py
      --num-gpus 16
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_cc6790emb/model_final.pth
      OUTPUT_DIR /mnt/output_storage/results/LSJ_train_CLIPfastrcnn_rn50_openset_strongfpn400eprpn_866ids_08bgloss_ourclip3m600kcc6790emb
      MODEL.ROI_HEADS.NUM_CLASSES 866
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_MASK_HEAD.CLS_AGNOSTIC_MASK True
      DATALOADER.NUM_WORKERS {num_workers}
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      SOLVER.BASE_LR 0.002
      SOLVER.WARMUP_ITERS 5000
      TEST.EVAL_PERIOD 75000
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/results/train_mask_rcnn_R_50_FPN_rpnonly_400ep_bs256_LSJ_LVIS_2nodes_16gpus/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_866_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA False
      MODEL.CLIP.BG_CLS_LOSS_WEIGHT 0.8
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.OFFLINE_RPN_LSJ_PRETRAINED True
    
    # only evaluation by multiplying RPN score
    - python3 ./tools/train_net.py
      --num-gpus 8
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      --eval-only
      MODEL.WEIGHTS /mnt/output_storage/results/LSJ_train_CLIPfastrcnn_rn50_openset_strongfpn400eprpn_866ids_08bgloss_ourclip3m600kcc6790emb/model_final.pth
      MODEL.ROI_HEADS.NUM_CLASSES 866
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_MASK_HEAD.CLS_AGNOSTIC_MASK True
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      SOLVER.BASE_LR 0.002
      SOLVER.WARMUP_ITERS 5000
      TEST.EVAL_PERIOD 75000
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/results/train_mask_rcnn_R_50_FPN_rpnonly_400ep_bs256_LSJ_LVIS_2nodes_16gpus/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_866_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA False
      MODEL.CLIP.BG_CLS_LOSS_WEIGHT 0.8
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.OFFLINE_RPN_LSJ_PRETRAINED True
      MODEL.CLIP.MULTIPLY_RPN_SCORE True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02

    submit_args:
      container_args:
        shm_size: 10240G
  max_trials: 1
  type: grid          
  params:
    - name: ims_per_batch
      spec: discrete
      values: [16]
    - name: num_workers
      spec: discrete
      values: [4]





# exp: train close-set/open-set Mask RCNN, with FPN/C4 backbone initialized by ImageNet vs. CLIP vs. random init 
# search:
#   job_template:
#     name: train_mask_rcnn_resnet50_CLIP_gpus8_bs16_lr0.002_1x_txtembclsfier
#     sku: G8 
#     sku_count: 1
#     command:
#     - nvidia-smi
#     - bash install.sh
#     - python3 ./tools/train_net.py
#       --num-gpus 8
#       --config-file ./configs/LVISv1-InstanceSegmentation/mask_rcnn_CLIP_R_50_FPN_1x.yaml
#       MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/RN50_OAI_CLIP.pth
#       OUTPUT_DIR /mnt/output_storage/results/train_mask_rcnn_resnet50_CLIP_gpus8_bs16_lr0.002_1x_txtembclsfier
#       SOLVER.IMS_PER_BATCH {ims_per_batch}
#       DATALOADER.NUM_WORKERS {num_workers}
#       SOLVER.BASE_LR 0.002
#       MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
#       MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb.pth
#       # MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
#       # MODEL.ROI_MASK_HEAD.CLS_AGNOSTIC_MASK True
      
#       #--config-file ./configs/LVISv1-InstanceSegmentation/mask_rcnn_CLIP_R_50_C4_1x.yaml
#       #--config-file ./configs/LVISv1-InstanceSegmentation/mask_rcnn_CLIP_R_50_FPN_1x.yaml
#       #--config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_CLIP_R_50_C4_1x.yaml
#       #MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/RN50_OAI_CLIP.pth
#       #MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/VITB32_OAI_CLIP.pth
#       #OUTPUT_DIR /mnt/output_storage/results/train_mask_rcnn_resnet50_CLIP_gpus8_bs16_lr0.002_1x

#       #MODEL.BACKBONE.FREEZE_AT 0
#       #SOLVER.WEIGHT_DECAY 0.001
#       #SOLVER.CLIP_GRADIENTS.ENABLED True  SOLVER.CLIP_GRADIENTS.CLIP_VALUE 1.0 

#     submit_args:
#       container_args:
#         shm_size: 1024G
#   max_trials: 1
#   type: grid          
#   params:
#     - name: ims_per_batch
#       spec: discrete
#       values: [16]
#     - name: num_workers
#       spec: discrete
#       values: [24]
