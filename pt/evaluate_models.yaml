description: train Mask RCNN on LVIS

target:
  vc: hcrr07 # hai1 # hcrr08 # hcrr07 # resrchvc  # 
  service: amlk8s
  name: ms-shared-v100 #  itphyperdgx2cl2 # ms-shared-v100 #  itpeastusv100cl # itpscusv100cl  #  itpseasiav100cl #  itplabrr1cl1  # 
  #subscription_id: 46da6261-2167-4e71-8b0d-f4a45215ce61

environment:
  image: wangkenpu/pytorch:1.8.0-py39-cuda11.1-cudnn8-ubuntu18.04 # amsword/setup:py36pt17u18cu11 # jw2yang/video-pytorch1.7:v0.1 
  registry: docker.io

storage:  
  # By default, the mount path is /mnt/data_storage, /mnt/output_storage
  data_storage:
    storage_account_name: vlpdatasets
    container_name: data
  output_storage:
    storage_account_name: vyiwuzhong
    container_name: phillytools 

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: ./


# exp: evaluate model CLIPFastRCNN trained on COCO-48 with RoIAlign to extract region features (GT / RPN regions) and offline localization module
search:
  job_template:
    #name: evaluate_lvisdetector_on_coco80_with_LSJ400epRPN
    name: evaluate_ablation_zeroshotinference_table4
    #name: visualization_ourclipcc3m600k_gtbox_lvis
    #name: evaluate_ablation_lvisdetector_fullysupervised_cc3m600k_strongrpn400ep
    #name: evaluate_model_cocozeroshotdetector_clip
    sku: G8 # G16 # G1 # 
    sku_count: 1
    # aml_mpirun:
    #   process_count_per_node: 1
    #   # AML only supports: OpenMpi or IntelMpi
    #   communicator: "OpenMpi"
    command:
    - nvidia-smi
    - bash install.sh
    - ulimit -n 64000
     
    # lvis detector, apply softnms
    # - python3 ./tools/train_net.py
    #   --num-gpus 16
    #   --eval-only
    #   --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIP_fast_rcnn_resnet50_supclipfpnrpn_temp001_ourclipcc3m600k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/results/train_mask_rcnn_R_50_FPN_rpnonly_400ep_bs256_LSJ_LVIS_2nodes_16gpus/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   SOLVER.BASE_LR 0.002
    #   SOLVER.WARMUP_ITERS 5000
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02
    #   MODEL.MASK_ON False
    #   MODEL.CLIP.OFFLINE_RPN_LSJ_PRETRAINED True
    #   MODEL.ROI_HEADS.SOFT_NMS_ENABLED True

    #   # MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_CLIP_R_50_FPN_1x.yaml
    #   # MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_clip_backbone_supervised/fpn/model_final.pth

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_openset_strongfpn400eprpn_866ids_08bgloss_ourclip3m600k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/results/train_mask_rcnn_R_50_FPN_rpnonly_400ep_bs256_LSJ_LVIS_2nodes_16gpus/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.ROI_HEADS.NUM_CLASSES 866
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_866_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   SOLVER.BASE_LR 0.002
    #   SOLVER.WARMUP_ITERS 5000
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_MASK_HEAD.CLS_AGNOSTIC_MASK True
    #   MODEL.CLIP.BG_CLS_LOSS_WEIGHT 0.8
    #   MODEL.CLIP.OPENSET_TEST_NUM_CLASSES 1203
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02
    #   MODEL.CLIP.OFFLINE_RPN_LSJ_PRETRAINED True
    #   MODEL.ROI_HEADS.SOFT_NMS_ENABLED True
    #   # MODEL.MASK_ON False

    # coco detector, apply softnms (base, target, all)
    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testb.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcc3m600k_step75k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.ROI_HEADS.SOFT_NMS_ENABLED True

    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testt.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcc3m600k_step75k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_17_target_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.ROI_HEADS.SOFT_NMS_ENABLED True

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcc3m600k_step75k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.ROI_HEADS.SOFT_NMS_ENABLED True

    # coco 80 evaluation
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_coco80.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/trained_models/train_CLIPfastrcnn_rn50_openset_strongfpn400eprpn_866ids_08bgloss_ourclip3m600kcc6790emb_mnodes/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/results/train_mask_rcnn_R_50_FPN_rpnonly_400ep_bs256_LSJ_LVIS_2nodes_16gpus/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.ROI_HEADS.NUM_CLASSES 80
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_80_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_MASK_HEAD.CLS_AGNOSTIC_MASK True
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.OFFLINE_RPN_LSJ_PRETRAINED True

    # ###################################################
    # for visualization
    # - python3 ./tools/train_net.py
    #   --num-gpus 16
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   OUTPUT_DIR /mnt/output_storage/results/visualization_ourclipcc3m600k_gtbox
    #   MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE GT
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE False
    #   # TEST.DETECTIONS_PER_IMAGE 20  #  keep it small, otherwise each gt box always has multiple predictions

    # - python3 ./tools/train_net.py
    #   --num-gpus 16
    #   --eval-only
    #   --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
    #   OUTPUT_DIR /mnt/output_storage/results/visualization_ourclipcc3m600k_gtbox_lvis
    #   MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE GT
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE False
    #   #MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02

    # ###################################################
    # evaluate ablation zeroshotinference our cliprn50x4
    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_teacherrn50x4_studentrn50x4/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm_rn50x4.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm_rn50x4.pth
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE False
      MODEL.RESNETS.DEPTH 200
      MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
      MODEL.CLIP.TEXT_EMB_DIM 640

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_teacherrn50x4_studentrn50x4/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm_rn50x4.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm_rn50x4.pth
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE True
      MODEL.RESNETS.DEPTH 200
      MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
      MODEL.CLIP.TEXT_EMB_DIM 640

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_teacherrn50x4_studentrn50x4/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm_rn50x4.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE False
      MODEL.RESNETS.DEPTH 200
      MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
      MODEL.CLIP.TEXT_EMB_DIM 640

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_teacherrn50x4_studentrn50x4/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm_rn50x4.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02
      MODEL.RESNETS.DEPTH 200
      MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
      MODEL.CLIP.TEXT_EMB_DIM 640

    # evaluate ablation zeroshotinference cliprn50x4
    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50x4_student_RN50x4_OAI_CLIP.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm_rn50x4.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm_rn50x4.pth
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE False
      MODEL.RESNETS.DEPTH 200
      MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
      MODEL.CLIP.TEXT_EMB_DIM 640

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50x4_student_RN50x4_OAI_CLIP.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm_rn50x4.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm_rn50x4.pth
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE True
      MODEL.RESNETS.DEPTH 200
      MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
      MODEL.CLIP.TEXT_EMB_DIM 640

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50x4_student_RN50x4_OAI_CLIP.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm_rn50x4.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE False
      MODEL.RESNETS.DEPTH 200
      MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
      MODEL.CLIP.TEXT_EMB_DIM 640

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50x4_student_RN50x4_OAI_CLIP.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm_rn50x4.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02
      MODEL.RESNETS.DEPTH 200
      MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
      MODEL.CLIP.TEXT_EMB_DIM 640


    # evaluate ablation zeroshotinference our cliprn50
    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE False

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE True

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE False

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02

    # evaluate ablation zeroshotinference cliprn50
    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50_student_RN50_OAI_CLIP.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE False

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50_student_RN50_OAI_CLIP.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE True

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50_student_RN50_OAI_CLIP.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE False

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50_student_RN50_OAI_CLIP.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.MULTIPLY_RPN_SCORE True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02
    
    # ###################################################
    # important pretrained ckpts
    # /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50_student_RN50_OAI_CLIP.pth
    # /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k/model_final.pth
    # /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_teacherrn50x4/model_final.pth
    # /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50x4_student_RN50x4_OAI_CLIP.pth
    
    # ablation study ckpts:
    # pretrain_rn50_frzt2_b48_only_glbimgmaxeotnormgather
    # pretrain_frzt2_b48_glbimg_cntrstkl_exp639_noglbimg
    # pretrain_rn50_frzt2_b48_glbimgmaxeotnormgather_cntrstkl_norm01thres_normtemp001_100of300regions_iou05

    # pretrain_frzt2_b48_glbimg_cntrstkl_exp639_gridbox_conceptthres0_run2
    # pretrain_frzt2_b48_glbimg_cntrstkl_exp639_randbox
    # pretrain_rn50_frzt2_b48_glbimgmaxeotnormgather_cntrstkl_norm01thres_normtemp001_100of300regions_iou05

    # pretrain_rn50_frzt2_b48_glbimgmaxeotnormgather_cntrstkl_norm01thres_normtemp001_100of300regions_iou05
    # dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k
    # dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_cc6250emb_run2

    # pretrain_frzt2_b48_glbimg_cntrstkl_exp639_conceptthres0_nokl
    # pretrain_frzt2_b48_glbimg_cntrstkl_exp639_conceptthres0_nocntrst
    # pretrain_rn50_frzt2_b48_glbimgmaxeotnormgather_cntrstkl_norm01thres_normtemp001_100of300regions_iou05

    # train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_1bgloss_normtemp001_gammano_ourclipcc3m400kteacherrn50x4  (focal scaling baseline)

    # coco zeroshot inference (ablation study), apply RPN scores
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/pretrain_rn50_frzt2_b48_only_glbimgmaxeotnormgather/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_noglbimg/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/pretrain_rn50_frzt2_b48_glbimgmaxeotnormgather_cntrstkl_norm01thres_normtemp001_100of300regions_iou05/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_gridbox_conceptthres0_run2/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_randbox/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_cc6250emb_run2/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_conceptthres0_nokl/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_conceptthres0_nocntrst/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    # ###################################################

    # - python3 ./tools/train_net.py
    #   --num-gpus 16
    #   --eval-only
    #   --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02
    #   # MODEL.ROI_HEADS.SOFT_NMS_ENABLED True
    #   # INPUT.MIN_SIZE_TEST 1200
    #   # INPUT.MAX_SIZE_TEST 2000

    # - python3 ./tools/train_net.py
    #   --num-gpus 16
    #   --eval-only
    #   --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50_student_RN50_OAI_CLIP.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02
    #   # MODEL.ROI_HEADS.SOFT_NMS_ENABLED True
    #   # INPUT.MIN_SIZE_TEST 1200
    #   # INPUT.MAX_SIZE_TEST 2000

    # ###################################################
    # cvpr pretrained model
    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/trained_models/cvpr_ovr_models/cvpr_ovr_pretrained_weights.pth
    #   MODEL.CLIP.CROP_REGION_TYPE GT
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco48_cls_emb.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco65_cls_emb.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE False
    #   MODEL.CLIP.RUN_CVPR_OVR True
    #   MODEL.META_ARCHITECTURE CLIPFastRCNN

    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/trained_models/cvpr_ovr_models/cvpr_ovr_pretrained_weights.pth
    #   MODEL.CLIP.CROP_REGION_TYPE GT
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco48_cls_emb.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco65_cls_emb.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 10.0
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE False
    #   MODEL.CLIP.RUN_CVPR_OVR True
    #   MODEL.META_ARCHITECTURE CLIPFastRCNN

    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/trained_models/cvpr_ovr_models/cvpr_ovr_pretrained_weights.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco48_cls_emb.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco65_cls_emb.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True
    #   MODEL.CLIP.RUN_CVPR_OVR True
    #   MODEL.META_ARCHITECTURE CLIPFastRCNN

    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --eval-only
    #   --config-file ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/trained_models/cvpr_ovr_models/cvpr_ovr_pretrained_weights.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco48_cls_emb.pth
    #   MODEL.CLIP.NO_BOX_DELTA True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/cvpr_ovr_models/coco65_cls_emb.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
    #   MODEL.ROI_HEADS.NMS_THRESH_TEST 0.5
    #   MODEL.CLIP.CLSS_TEMP 10.0
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True
    #   MODEL.CLIP.RUN_CVPR_OVR True
    #   MODEL.META_ARCHITECTURE CLIPFastRCNN

    # test all categories with RPN
    #################################################### only image-text level ####################################################
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma1_ourcliponlyglbimglevel/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01
    
    #################################################### image-text level + region-text level contrastive loss ####################################################
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipgridboxnokl/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourcliprandboxcncptthres0nokl/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourcliprpnboxnokl/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    #################################################### image-text level + region-text level classification loss ####################################################

    # # - python3 ./tools/train_net.py
    # #   --num-gpus 8
    # #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    # #   --eval-only
    # #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipglbboxnocntrst/model_0064999.pth
    # #   MODEL.CLIP.CROP_REGION_TYPE RPN
    # #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    # #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    # #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    # #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    # #   MODEL.CLIP.NO_BOX_DELTA False
    # #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    # #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    # #   MODEL.MASK_ON False
    # #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    # #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipgridboxnocntrst/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourcliprandboxthres0nocntrst/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourcliprpnboxnocntrst/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01


    #################################################### image-text level + region-text level classification & contrastive loss ####################################################

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipgridbox/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01


    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcocorandboxcncptthres0/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01
    
    # ***
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipglbimg1cntrst1kl_run2/model_0004999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipglbimg1cntrst1kl_run2/model_0014999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipglbimg1cntrst1kl_run2/model_0024999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipglbimg1cntrst1kl_run2/model_0044999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipglbimg1cntrst1kl_run2/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipglbimg1cntrst1kl_run2/model_0089999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01


    # original run
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIP_fast_rcnn_resnet50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_glbimg1cntrst1kl/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01


    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIP_fast_rcnn_resnet50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcocostrongfpn400ep/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    #################################################### region-text level classification & contrastive loss ####################################################
    # ***
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcntrstkl/model_0004999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcntrstkl/model_0014999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcntrstkl/model_0024999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcntrstkl/model_0044999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcntrstkl/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcntrstkl/model_0089999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01


    #################################################### pretraining on CC3M ####################################################

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclip3m600kcc6790emb/model_0064999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    ################################################################################################################################################################
    ################################################################################################################################################################
    ################################################################################################################################################################

    # FPN-RPN + trained by longer time      
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kcc6790emb_3x/model_0004999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/fpn/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01
      
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kcc6790emb_3x/model_0014999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/fpn/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01
      
    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kcc6790emb_3x/model_0024999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/fpn/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kcc6790emb_3x/model_0034999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/fpn/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kcc6790emb_3x/model_0044999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/fpn/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kcc6790emb_3x/model_0054999.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/fpn/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01


    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kcc6790emb_3x/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/fpn/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kcc6790emb_3x/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/fpn/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   MODEL.CLIP.MULTIPLY_RPN_SCORE True

    ################################################################################################################################################################
    ################################################################################################################################################################
    ################################################################################################################################################################

    # # - python3 ./tools/lazyconfig_train_net.py
    # #   --num-gpus 8
    # #   --config-file ./configs/new_baselines/clip_fast_rcnn_R_50_C4_100ep_LSJ_COCO_bs64.py
    # #   --eval-only
    # # /mnt/output_storage/results/train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kcc6790emb_3x/model_final.pth
    # # /mnt/output_storage/results/LSJ_train_CLIPfrcnn_rn50_coco48_FSDfpnrpn_02bgloss_normtemp001_gamma05_ourclip3m600kcc6790emb_gpus16_bs64/model_final.pth
    # # /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcc3m600kstrongrpn400ep/model_final.pth
    # # /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcc3m600k/model_final.pth
    

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipcc3m600k/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01


    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIP_fast_rcnn_resnet50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma1_clip/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # - python3 ./tools/train_net.py
    #   --num-gpus 8
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIP_fast_rcnn_resnet50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma1_clip/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE GT
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    submit_args:
      container_args:
        shm_size: 10240G
  max_trials: 1
  type: grid          
