description: pretrain region representation

target:
  vc: hcrr08 # hcrr08 # hcrr07 # hai1 #resrchvc  # 
  service: amlk8s
  name: itphyperdgx2cl2 # itphyperdgx2cl2 # ms-shared-v100 #  itpscusv100cl  #  itpseasiav100cl #  itplabrr1cl1  # 
  #subscription_id: 46da6261-2167-4e71-8b0d-f4a45215ce61

environment:
  image: wangkenpu/pytorch:1.8.0-py39-cuda11.1-cudnn8-ubuntu18.04 # amsword/setup:py36pt17u18cu11 # jw2yang/video-pytorch1.7:v0.1 
  registry: docker.io  # Authentication failed for container registry registry.hub.docker.com

storage:  
  # By default, the mount path is /mnt/data_storage, /mnt/output_storage
  data_storage:
    storage_account_name: vlpdatasets
    container_name: data
  output_storage:
    storage_account_name: vyiwuzhong
    container_name: phillytools 

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: ./

search:
  job_template:
    name: pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg
    sku: G16 # G8 # G1 # 
    sku_count: 1
    # sku_count: 2
    # aml_mpirun:
    #   process_count_per_node: 1
    #   # AML only supports: OpenMpi or IntelMpi
    #   communicator: "OpenMpi"
    command:
    - nvidia-smi
    - bash install.sh
    - ulimit -n 64000
    # - ifconfig
    # - export GLOO_SOCKET_IFNAME=eth0
    # - export MKL_SERVICE_FORCE_INTEL=1
    # - MKL_THREADING_LAYER=GNU python3 -m launch --nnodes=2 --nproc_per_node=8 --master_port 12345 ./tools/train_net.py 
    - python3 ./tools/train_net.py
      --num-gpus 16
      --config-file ./configs/clip_configs/clip_resnet_coco_vc.yaml
      MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/teacher_RN50_student_RN50_OAI_CLIP.pth
      OUTPUT_DIR /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.5
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      SOLVER.BASE_LR 0.001
      MODEL.BACKBONE.FREEZE_AT 2
      MODEL.CLIP.GATHER_GPUS True
      MODEL.CLIP.GRID_REGIONS False
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.CLIP.PRETRAIN_IMG_TXT_LEVEL True
      MODEL.CLIP.PRETRAIN_ONLY_EOT True
      MODEL.CLIP.CONCEPT_THRES 0.1
      MODEL.CLIP.PRETRAIN_RPN_REGIONS 300
      MODEL.CLIP.PRETRAIN_SAMPLE_REGIONS 100
      # MODEL.CLIP.CONCEPT_POOL_EMB /mnt/output_storage/trained_models/concept_pool/coco_nouns_4764_emb.pth
      # MODEL.CLIP.TEACHER_RESNETS_DEPTH 200
      # MODEL.CLIP.TEACHER_CONCEPT_POOL_EMB /mnt/output_storage/trained_models/concept_pool/coco_nouns_4764_emb_rn50x4.pth
      # MODEL.CLIP.TEACHER_POOLER_RESOLUTION 18
      # MODEL.CLIP.OFFLINE_RPN_LSJ_PRETRAINED True
      # SOLVER.MAX_ITER 25000
      # TEST.EVAL_PERIOD 5000
      
      # MODEL.WEIGHTS /mnt/output_storage/trained_models/oai_clip_weights/RN50_OAI_CLIP.pth
      # MODEL.WEIGHTS /mnt/output_storage/results/pretrain_fastrcnn_resnet50_coco_freezeat2_b192_sumtxt_temp10/model_0019999.pth
      # MODEL.WEIGHTS /mnt/output_storage/results/pretrain_fastrcnn_resnet50_coco_freezeat2_b192_sumtxt_temp10_gridfeat/model_0019999.pth
      # MODEL.WEIGHTS /mnt/output_storage/results/pretrain_fastrcnn_resnet50_coco_freezeat2_b96_sumtxt_temp10_gather/model_0024999.pth
      # MODEL.WEIGHTS /mnt/output_storage/results/pretrain_fastrcnn_rn50_coco_freezeat2_b48_noimgtxt_2ndmatch_09thres_temp10/model_final.pth
      # MODEL.WEIGHTS /mnt/output_storage/results/pretrain_fastrcnn_rn50_coco_freezeat2_b48_noimgtxt_2ndmatch_09thres_temp10_initbyourclip/model_final.pth
      
      # MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      # MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/results/train_mask_rcnn_R_50_FPN_rpnonly_400ep_bs256_LSJ_LVIS_2nodes_16gpus/model_final.pth
    
    # zeroshot inference with GT boxes
    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.CLIP.CLSS_TEMP 0.01

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.CLIP.CLSS_TEMP 0.1

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.CLIP.CLSS_TEMP 1.0

    # zeroshot inference with RPN boxes
    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.CLIP.CLSS_TEMP 1.0

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.CLIP.CLSS_TEMP 0.1

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.CLIP.CLSS_TEMP 0.01
    
    # LVIS zeroshot inference
    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.6
      MODEL.CLIP.CLSS_TEMP 0.1

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.6
      MODEL.CLIP.CLSS_TEMP 0.01

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.6
      MODEL.CLIP.CLSS_TEMP 0.1

    - python3 ./tools/train_net.py
      --num-gpus 8
      --eval-only
      --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
      MODEL.CLIP.CROP_REGION_TYPE GT
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_openset/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm.pth
      MODEL.CLIP.NO_BOX_DELTA True
      MODEL.MASK_ON False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
      MODEL.CLIP.OFFLINE_RPN_NMS_THRESH 0.9
      MODEL.ROI_HEADS.NMS_THRESH_TEST 0.6
      MODEL.CLIP.CLSS_TEMP 0.01
    
    ###############################################################################################################################################
    # - nvidia-smi
    # - nvidia-smi
    # - nvidia-smi
    # - nvidia-smi

    # # train zero-shot detector, tested by target AP
    # - python3 ./tools/train_net.py
    #   --num-gpus 16
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd.yaml
    #   MODEL.WEIGHTS /mnt/output_storage/results/pretrain_frzt2_b48_glbimg_cntrstkl_exp639_onlyglbimg/model_final.pth
    #   OUTPUT_DIR /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipteacherrn50x4
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.ROI_HEADS.NUM_CLASSES 48
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   SOLVER.IMS_PER_BATCH {ims_per_batch}
    #   DATALOADER.NUM_WORKERS {num_workers}
    #   SOLVER.BASE_LR 0.002
    #   SOLVER.WARMUP_ITERS 5000
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.ROI_MASK_HEAD.CLS_AGNOSTIC_MASK True
    #   MODEL.CLIP.BG_CLS_LOSS_WEIGHT 0.2
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   TEST.EVAL_PERIOD 25000
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.FOCAL_SCALED_LOSS 0.5
    #   MODEL.CLIP.CLSS_TEMP 0.01
    #   #MODEL.CLIP.MULTIPLY_RPN_SCORE True
    #   #MODEL.ROI_HEADS.POSITIVE_FRACTION 1.0
    #   # MODEL.CLIP.ONLY_SAMPLE_FG_PROPOSALS True
    #   #MODEL.BACKBONE.FREEZE_AT 5
    #   #MODEL.ROI_HEADS.PROPOSAL_APPEND_GT False

    # # test all categories with RPN
    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipteacherrn50x4/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # # test all categories with GT
    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testall.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipteacherrn50x4/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE GT
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_65_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # # test base categories with RPN
    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testb.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipteacherrn50x4/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # # test base categories with GT
    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testb.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipteacherrn50x4/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE GT
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # # test target categories with RPN
    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testt.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipteacherrn50x4/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE RPN
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_17_target_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    # # test target categories with GT
    # - python3 ./tools/train_net.py
    #   --num-gpus 4
    #   --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_testt.yaml
    #   --eval-only
    #   MODEL.WEIGHTS /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco48_FSDc4rpn_02bgloss_normtemp001_gamma05_ourclipteacherrn50x4/model_final.pth
    #   MODEL.CLIP.CROP_REGION_TYPE GT
    #   MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
    #   MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco48_FSD/c4/model_final.pth
    #   MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
    #   MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_48_base_cls_emb_notnorm.pth
    #   MODEL.CLIP.NO_BOX_DELTA False
    #   MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG True
    #   MODEL.CLIP.OPENSET_TEST_TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_17_target_cls_emb_notnorm.pth
    #   MODEL.MASK_ON False
    #   MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
    #   MODEL.CLIP.CLSS_TEMP 0.01

    submit_args:
      container_args:
        shm_size: 10240G
  max_trials: 1
  type: grid          
  params:
    - name: ims_per_batch
      spec: discrete
      values: [48]
    - name: num_workers
      spec: discrete
      values: [2]