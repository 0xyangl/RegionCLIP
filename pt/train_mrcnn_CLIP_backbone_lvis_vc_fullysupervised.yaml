description: train Mask RCNN on LVIS

target:
  vc: hcrr07 # hcrr07 # hai1 # hcrr08 # hcrr07 # resrchvc  # 
  service: amlk8s
  name: ms-shared-v100 # itphyperdgx2cl2 # ms-shared-v100 #  itpeastusv100cl # itpscusv100cl  #  itpseasiav100cl #  itplabrr1cl1  # 
  #subscription_id: 46da6261-2167-4e71-8b0d-f4a45215ce61

environment:
  image: wangkenpu/pytorch:1.8.0-py39-cuda11.1-cudnn8-ubuntu18.04 # amsword/setup:py36pt17u18cu11 # jw2yang/video-pytorch1.7:v0.1 
  registry: docker.io

storage:  
  # By default, the mount path is /mnt/data_storage, /mnt/output_storage
  data_storage:
    storage_account_name: vlpdatasets
    container_name: data
  output_storage:
    storage_account_name: vyiwuzhong
    container_name: phillytools 

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: ./

# exp: CLIPFastRCNN COCO-48 training with RoIAlign to extract region features (GT / RPN regions) and offline localization module
search:
  job_template:
    name: train_CLIPfastrcnn_rn50_coco80_FSDc4rpnwomask_1bgloss_normtemp001_gammano_ourcliprn50x4ckpt600k
    sku: G16 # G1 # 
    sku_count: 1
    # aml_mpirun:
    #   process_count_per_node: 1
    #   # AML only supports: OpenMpi or IntelMpi
    #   communicator: "OpenMpi"
    command:
    - nvidia-smi
    - bash install.sh
    - ulimit -n 64000
    # train COCO-80 supervised detector, tested by all AP
    - python3 ./tools/train_net.py
      --num-gpus 16
      --config-file ./configs/COCO-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4_ovd_coco80.yaml
      MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_teacherrn50x4_studentrn50x4/model_final.pth
      OUTPUT_DIR /mnt/output_storage/results/train_CLIPfastrcnn_rn50_coco80_FSDc4rpnwomask_1bgloss_normtemp001_gammano_ourcliprn50x4ckpt600k
      MODEL.CLIP.CROP_REGION_TYPE RPN
      MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x_ovd_FSD.yaml
      MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_coco80/c4/model_final.pth
      MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
      MODEL.ROI_HEADS.NUM_CLASSES 80
      MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/coco_80_cls_emb_notnorm_rn50x4.pth
      MODEL.CLIP.NO_BOX_DELTA False
      SOLVER.IMS_PER_BATCH {ims_per_batch}
      DATALOADER.NUM_WORKERS {num_workers}
      SOLVER.BASE_LR 0.002
      SOLVER.WARMUP_ITERS 5000
      MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG False
      MODEL.ROI_MASK_HEAD.CLS_AGNOSTIC_MASK True
      MODEL.CLIP.BG_CLS_LOSS_WEIGHT 1.0
      MODEL.MASK_ON False
      TEST.EVAL_PERIOD 25000
      MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.001
      MODEL.CLIP.FOCAL_SCALED_LOSS None
      MODEL.CLIP.CLSS_TEMP 0.01
      MODEL.RESNETS.DEPTH 200
      MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
      MODEL.CLIP.TEXT_EMB_DIM 640

    submit_args:
      container_args:
        shm_size: 10240G
  max_trials: 1
  type: grid          
  params:
    - name: ims_per_batch
      spec: discrete
      values: [16]
    - name: num_workers
      spec: discrete
      values: [4]


# exp: CLIPFastRCNN LVIS/COCO supervised training with RoIAlign to extract region features (GT / RPN regions) and offline localization module
# search:
#   job_template:
#     name: train_CLIP_fast_rcnn_resnet50_supclipfpnrpn_temp001_ourcliprn50x4ckpt600k
#     sku: G16 # G1 # 
#     sku_count: 1
#     command:
#     - nvidia-smi
#     - bash install.sh
#     - ulimit -n 64000
#     # training
#     - python3 ./tools/train_net.py
#       --num-gpus 16
#       --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
#       MODEL.WEIGHTS /mnt/output_storage/results/dpretrain_frzt2_b96_glbimg_cntrstkl_exp639_lr0002_cc3m_600k_teacherrn50x4_studentrn50x4/model_final.pth
#       OUTPUT_DIR /mnt/output_storage/results/train_CLIP_fast_rcnn_resnet50_supclipfpnrpn_temp001_ourcliprn50x4ckpt600k
#       MODEL.CLIP.CROP_REGION_TYPE RPN
#       MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_CLIP_R_50_FPN_1x.yaml
#       MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_clip_backbone_supervised/fpn/model_final.pth
#       MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
#       MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm_rn50x4.pth
#       MODEL.CLIP.NO_BOX_DELTA False
#       SOLVER.IMS_PER_BATCH {ims_per_batch}
#       DATALOADER.NUM_WORKERS {num_workers}
#       SOLVER.BASE_LR 0.002
#       SOLVER.WARMUP_ITERS 5000
#       MODEL.CLIP.CLSS_TEMP 0.01
#       TEST.EVAL_PERIOD 25000
#       MODEL.MASK_ON True
#       MODEL.RESNETS.DEPTH 200
#       MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
#       MODEL.CLIP.TEXT_EMB_DIM 640
#       MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION 18
#       MODEL.RESNETS.RES2_OUT_CHANNELS 320
    
#     # evaluation (multiply RPN scores)
#     - python3 ./tools/train_net.py
#       --num-gpus 16
#       --eval-only
#       --config-file ./configs/LVISv1-InstanceSegmentation/CLIP_fast_rcnn_R_50_C4.yaml
#       MODEL.WEIGHTS /mnt/output_storage/results/train_CLIP_fast_rcnn_resnet50_supclipfpnrpn_temp001_ourcliprn50x4ckpt600k/model_final.pth
#       MODEL.CLIP.CROP_REGION_TYPE RPN
#       MODEL.CLIP.OFFLINE_RPN_CONFIG ./configs/LVISv1-InstanceSegmentation/mask_rcnn_CLIP_R_50_FPN_1x.yaml
#       MODEL.CLIP.BB_RPN_WEIGHTS /mnt/output_storage/trained_models/mrcnn_clip_backbone_supervised/fpn/model_final.pth
#       MODEL.CLIP.USE_TEXT_EMB_CLASSIFIER True
#       MODEL.CLIP.TEXT_EMB_PATH /mnt/output_storage/trained_models/lvis_cls_emb/lvis_1203_cls_emb_notnorm_rn50x4.pth
#       MODEL.CLIP.NO_BOX_DELTA False
#       SOLVER.IMS_PER_BATCH {ims_per_batch}
#       DATALOADER.NUM_WORKERS {num_workers}
#       SOLVER.BASE_LR 0.002
#       SOLVER.WARMUP_ITERS 5000
#       MODEL.CLIP.CLSS_TEMP 0.01
#       MODEL.CLIP.MULTIPLY_RPN_SCORE True
#       MODEL.ROI_HEADS.SCORE_THRESH_TEST 0.02
#       MODEL.MASK_ON True
#       MODEL.RESNETS.DEPTH 200
#       MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION 18
#       MODEL.CLIP.TEXT_EMB_DIM 640
#       MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION 18
#       MODEL.RESNETS.RES2_OUT_CHANNELS 320
      
#     submit_args:
#       container_args:
#         shm_size: 10240G
#   max_trials: 1
#   type: grid          
#   params:
#     - name: ims_per_batch
#       spec: discrete
#       values: [16]
#     - name: num_workers
#       spec: discrete
#       values: [4]
